# Ministral 3 3B Local Setup Guide with MCP Tool Calling

Everyone's talking about Ministral 3 3B, so I wanted to see what the hype is about. ðŸ¤¨

This guide covers:
- What makes Ministral 3 3B special
- How to run it locally with Ollama
- Setting up Open WebUI with Docker
- Testing local Python tools
- Working with remote MCP tools via Composio

## What's so Special?

Ministral 3 3B is the smallest model in the Mistral 3 family with:
- **256K token context window**
- **Function calling** and structured output
- **Vision capabilities** (multimodal)
- **WebGPU support** (runs in browser)
- **Apache 2.0 license** (fully open source)

### Key Features
- Vision: Analyze images alongside text
- Multilingual: Supports dozens of languages
- Agentic: Native function calling and JSON output
- Local: Runs completely in browser with WebGPU

*Content converted from Notion page - Full guide available at original source*

---

**Note:** This is an automated conversion from Notion. For the complete guide with images and detailed instructions, please refer to the original Notion page.